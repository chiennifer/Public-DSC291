{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute once when starting cluster\n",
    "\n",
    "# s3helper.open_bucket('mas-dse-open',region='us-west-2')\n",
    "# info_files=s3helper.ls('Weather/Info')\n",
    "# Without_path=[x[13:] for x in info_files]\n",
    "# !mkdir /mnt/workspace/WeatherInfo\n",
    "# for i in range(len(info_files)-1):   # Last entry is the directory name\n",
    "#     _from=info_files[i]\n",
    "#     _to='/mnt/workspace/WeatherInfo/'+Without_path[i]\n",
    "#     print('From %s to %s'%(_from,_to))\n",
    "#     s3helper.s3_to_local(_from,_to)\n",
    "    \n",
    "    \n",
    "# s3helper.open_bucket('dse-weather-west-2', region=\"us-west-2\")\n",
    "# s3helper.ls('')\n",
    "\n",
    "# s3helper.local_to_s3(\"/home/hadoop/s3helper.py\", \"fromLocal/s3helper.py\")\n",
    "\n",
    "\n",
    "# s3helper.s3_to_hdfs(\"weather.parquet\", \"/tmp/weather.parquet\")\n",
    "\n",
    "# s3helper.s3_to_hdfs(\"info/stations.parquet\", \"/tmp/stations.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----+--------------------+\n",
      "|    Station|Measurement|Year|              Values|\n",
      "+-----------+-----------+----+--------------------+\n",
      "|USW00093819|       WDFM|1972|[38 58 EC 5C 38 5...|\n",
      "|USW00093819|       WDFM|1973|[38 5C EC 5C 08 5...|\n",
      "|USW00093819|       WDFM|1974|[EC 5C A0 51 EC 5...|\n",
      "|USW00093819|       WDFM|1975|[EC 5C 38 58 38 5...|\n",
      "|USW00093819|       WDFM|1976|[38 58 38 58 38 5...|\n",
      "|USW00093819|       WDFM|1977|[EC 5C 38 5C A0 5...|\n",
      "|USW00093819|       WDFM|1978|[38 5C 08 5B EC 5...|\n",
      "|USW00093819|       WDFM|1979|[EC 5C 38 5C 08 5...|\n",
      "|USW00093819|       WESD|1952|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1953|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1954|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1955|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1956|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1957|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1958|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1959|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1960|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1961|[00 7E 00 7E 00 7...|\n",
      "|USW00093819|       WESD|1962|[A0 53 A0 53 60 5...|\n",
      "|USW00093819|       WESD|1963|[00 7E 00 7E 00 7...|\n",
      "+-----------+-----------+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run every time notebook restarted\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.sql(\"SELECT * FROM parquet.`/tmp/weather.parquet`\")\n",
    "\n",
    "stations=sqlContext.sql(\"SELECT * FROM parquet.`/tmp/stations.parquet`\")\n",
    "\n",
    "print(df.count())\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "    pandas as    pd \tversion=0.19.2 \trequired version>=0.19.2\n",
      "\n",
      "     numpy as    np \tversion=1.11.3 \trequired version>=1.12.0\n",
      "******* Update Version ******\n",
      "   sklearn as    sk \tversion=0.18.1 \trequired version>=0.18.1\n",
      "\n",
      "module urllib has no version\n",
      "   pyspark as pyspark \tversion=2.3.0 \trequired version>=2.1.0\n",
      "\n",
      "ipywidgets as ipywidgets \tversion=5.2.2 \trequired version>=6.0.0\n",
      "******* Update Version ******\n",
      "version of ipwidgets= 5.2.2\n"
     ]
    }
   ],
   "source": [
    "# Enable automiatic reload of libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # means that all modules are reloaded before every command\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/mnt/workspace/Public-DSC291/notebooks/Section2-PCA/Section2-Weather-PCA_PART2')\n",
    "\n",
    "from lib.numpy_pack import packArray,unpackArray\n",
    "#from lib.Eigen_decomp import Eigen_decomp\n",
    "from lib.YearPlotter import YearPlotter\n",
    "from lib.decomposer import *\n",
    "from lib.Reconstruction_plots import *\n",
    "\n",
    "\n",
    "from lib.import_modules import import_modules,modules\n",
    "import_modules(modules)\n",
    "\n",
    "from lib.getFiles import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print('version of ipwidgets=',widgets.__version__)\n",
    "\n",
    "import warnings  # Suppress Warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA.parquet  oni.data  STAT_CA.pickle  stations.parquet\r\n"
     ]
    }
   ],
   "source": [
    "data_dir='../Data/Weather'\n",
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "pref = '/mnt/workspace/Public-DSC291/notebooks/Section2-PCA/Section2-Weather-PCA_PART2/'\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=[pref+'lib/numpy_pack.py',\n",
    "                                             pref+'lib/spark_PCA.py',\n",
    "                                             pref+'lib/computeStatistics.py',\n",
    "                                             pref+'lib/Reconstruction_plots.py',\n",
    "                                             pref+'lib/decomposer.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl https://mas-dse-open.s3.amazonaws.com/Weather/by_state_2/CA.tgz > ../Data/Weather/CA.tgz\n",
      "tar -xzf ../Data/Weather/CA.tgz -C ../Data/Weather\n",
      "rm ../Data/Weather/CA.tgz\n",
      "curl https://mas-dse-open.s3.amazonaws.com/Weather/by_state_2/STAT_CA.pickle.gz > ../Data/Weather/STAT_CA.pickle.gz\n",
      "gunzip ../Data/Weather/STAT_CA.pickle.gz\n",
      "curl https://mas-dse-open.s3.amazonaws.com/Weather/Weather_Stations.tgz > ../Data/Weather/Weather_Stations.tgz\n",
      "tar -xzf ../Data/Weather/Weather_Stations.tgz -C ../Data/Weather\n",
      "rm ../Data/Weather/Weather_Stations.tgz\n",
      "133M\t../Data/Weather/CA.parquet\n",
      "420K\t../Data/Weather/stations.parquet\n",
      "182M\t../Data/Weather\n",
      "keys from STAT= dict_keys(['TMIN', 'TMAX', 'TMAX_s20', 'SNOW', 'SNWD', 'SNWD_s20', 'SNOW_s20', 'TMIN_s20', 'PRCP', 'TOBS_s20', 'TOBS', 'PRCP_s20'])\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "import os\n",
    "\n",
    "state='CA'\n",
    "\n",
    "get_weather_files(state,data_dir)\n",
    "!du -h $data_dir\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%state\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "measurements=STAT.keys()\n",
    "print('keys from STAT=',measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m='PRCP_s20'\n",
    "\n",
    "Mean=STAT[m]['Mean']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
